{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW00: CODING ENVIRONMENT SETUP AND, INTRODUCTION TO PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Assignment 00 for the course \"Introduction to Data Science\" at the Faculty of Information Technology, University of Science, Vietnam National University, Ho Chi Minh City."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Latest update: 09/08/2024)\n",
    "\n",
    "Student Name:\n",
    "\n",
    "Student ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assignment Objectives**\n",
    "\n",
    "In this assignment, we will introduce you to setting up a Python environment with Anaconda and familiarize you with the Python programming language. Additionally, we will introduce some basic data types that you will frequently encounter in the future, including digital images and text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **How to Complete and Submit the Assignment**\n",
    "\n",
    "&#9889; **Note**: You should follow the instructions below. If anything is unclear, you need to contact the teaching assistant or instructor immediately for timely support.\n",
    "\n",
    "**How to Do the Assignment**\n",
    "\n",
    "You will work directly on this notebook file. First, fill in your full name and student ID (MSSV) in the header section of the file above. In the file, complete the tasks in sections marked:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "Or for optional code sections:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "For markdown cells, complete the answer in the section marked:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "\n",
    "**How to Submit the Assignment**\n",
    "\n",
    "Before submitting, select `Kernel` -> `Restart Kernel & Run All Cells` if you are using a local environment, or `Runtime -> Restart session` and run all if using Google Colab, to ensure everything works as expected.\n",
    "\n",
    "Next, create a submission folder with the following structure:\n",
    "- Folder named `MSSV` (for example, if your student ID is `1234567`, name the folder `1234567`)\n",
    "    - File `HW00.ipynb` (no need to submit other files)\n",
    "\n",
    "Finally, compress this `MSSV` folder in `.zip` format (not `.rar` or any other format) and submit it via the link on Moodle.\\\n",
    "<font color=red>Please make sure to strictly follow this submission guideline.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.data import camera\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkingPlatform() -> dict:\n",
    "    \"\"\"\n",
    "    Retrieves platform-related information for the current operating system environment.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the following platform information:\n",
    "            - 'platform_system': The system/OS name, e.g., 'Linux', 'Windows', etc.\n",
    "            - 'os_name': The name of the operating system dependent module imported, e.g., 'posix', 'nt', etc.\n",
    "            - 'sys_platform': A string representing the platform the script is running on, e.g., 'linux', 'win32', etc.\n",
    "            - 'platform_release': The release version of the operating system.\n",
    "            - 'platform_version': The detailed version of the operating system.\n",
    "            - 'platform_description': A string that combines various platform details.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'platform_system': platform.system(),\n",
    "        'os_name': os.name,\n",
    "        'sys_platform': sys.platform,\n",
    "        'platform_release': platform.release(),\n",
    "        'platform_version': platform.version(),\n",
    "        'platform_description': platform.platform()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your coding environment\n",
    "\n",
    "This section is used to check your programming environment. I don’t care which operating system you are using (Windows 11/10 or any Linux distribution). You need to set up the environment that works best for you on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkingPlatform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Based on your knowledge of Python libraries for Data Science, give a brief introduction to one of them.\n",
    "\n",
    "In this question, you're expected to select a popular Python library used in Data Science and provide a concise introduction. For example, you might choose to introduce a library like NumPy. Your response should follow this outline:\n",
    "\n",
    "1. Library Introduction:\n",
    "- Start by identifying the library you’ve chosen. Provide a brief history or background about the library, including its purpose and when it was developed.\n",
    "- Discuss its popularity and significance in the Data Science ecosystem.\n",
    "2. Role in Data Science:\n",
    "- Explain how this library supports common Data Science tasks. Highlight the specific types of operations or challenges that it simplifies (e.g., data manipulation, statistical analysis, numerical computing, etc.).\n",
    "- Mention key features or advantages that make this library indispensable for Data Scientists.\n",
    "3. Function Usage and Examples:\n",
    "- Demonstrate the library's usage with one or two small code examples. Focus on core functionality that shows its relevance in real-world applications (e.g., matrix manipulation, statistical calculations, or data visualization).\n",
    "- Explain the code snippets and provide context on how these functions can be applied to typical Data Science problems.\n",
    "\n",
    "For example, NumPy plays a crucial role in Data Science by enabling efficient storage and manipulation of numerical data. It simplifies tasks such as:\n",
    "- Array operations: NumPy allows for fast element-wise operations on large datasets, which is essential for data analysis and preprocessing.\n",
    "- Mathematical functions: It offers a wide range of mathematical functions, such as linear algebra operations, statistical functions, and Fourier transforms.\n",
    "- Interoperability: NumPy integrates seamlessly with other libraries like Pandas, Matplotlib, and SciPy, enhancing its utility in the Data Science workflow.\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "array = np.array([10, 20, 30, 40])\n",
    "print(\"Original Array:\", array)\n",
    "\n",
    "mean_value = np.mean(array)\n",
    "std_dev = np.std(array)\n",
    "print(\"Mean:\", mean_value)\n",
    "print(\"Standard Deviation:\", std_dev)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Giới thiệu thư viện Pandas `pandas`\n",
    "\n",
    "#### Pandas là gì?\n",
    "\n",
    "Pandas là một thư viện Python được thiết kế để làm việc với dữ liệu có cấu trúc (VD: dữ liệu dạng bảng như file Excel, các cơ sở dữ liệu, dữ liệu đa chiều). \n",
    "\n",
    "Pandas cung cấp các cấu trúc dữ liệu mạnh mẽ và linh hoạt, cùng các hàm phong phú để thao tác, làm sạch, phân tích và trực quan hóa dữ liệu.\n",
    "\n",
    "*Funfact: \"Pandas\" được lấy ý tưởng từ 2 cụm \"Panel Data\" và \"Python Data Analysis\", được phát triển bởi Wes MCKinney vào năm 2008.*\n",
    "\n",
    "#### Vai trò của Pandas trong Khoa học dữ liệu\n",
    "\n",
    "**Thao tác với dữ liệu:** Pandas có các hàm giúp dễ dàng đọc dữ liệu từ nhiều nguồn khác nhau (CSV, Excel, SQL,...) và làm sạch dữ liệu bằng cách xử lí các giá trị thiếu, trùng lặp.\n",
    "\n",
    "**Phân tích dữ liệu:** Cung cấp các hàm thực hiện các phép thống kê, lọc, nhóm, sắp xếp và tính toán các chỉ số quan trọng trong dữ liệu.\n",
    "\n",
    "**Chuẩn bị dữ liệu cho mô hình**: Ta có thể dùng Pandas để chuẩn bị dữ liệu để dưa vào các mô hình học máy, như: mã hóa các biến category, chia dữ liệu thành các tập (test, validation, train).\n",
    "\n",
    "#### Sử dụng và ví dụ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Tạo DataFrame từ một dictionary\n",
    "data = {'Quả': ['Táo', 'Chuối', 'Cam'],\n",
    "        'Số lượng': [10, 15, 8],\n",
    "        'Giá': [15000, 12000, 18000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Hiển thị DataFrame\n",
    "print(df)\n",
    "\n",
    "# Truy cập cột\n",
    "print(df['Quả'])\n",
    "\n",
    "# Lọc dữ liệu\n",
    "print(df[df['Số lượng'] > 10])\n",
    "\n",
    "# Tính toán thống kê\n",
    "print(df['Giá'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Digital Image Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read digital image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gaussian_pyramid(ima, levelmax):\n",
    "    \"\"\"return a list of subsampled images (using gaussion pre-filter\"\"\"\n",
    "    r = [ima]\n",
    "    current = ima\n",
    "    for level in range(levelmax):\n",
    "        lp = gaussian_filter(current, 1.0)\n",
    "        sub = lp[::2, ::2]\n",
    "        current = sub\n",
    "        r.append(current)\n",
    "    return r\n",
    "\n",
    "\n",
    "def build_pyramid(ima, levelmax):\n",
    "    \"\"\"return a list of subsampled images (using gaussion pre-filter\"\"\"\n",
    "    r = [ima]\n",
    "    current = ima\n",
    "    for level in range(levelmax):\n",
    "        sub = current[::2, ::2]\n",
    "        current = sub\n",
    "        r.append(current)\n",
    "    return r\n",
    "\n",
    "\n",
    "im = camera()[::2, ::2]\n",
    "\n",
    "# build filtered and non-filtered pyramids\n",
    "N = 4\n",
    "fpyramid = build_gaussian_pyramid(im, N)\n",
    "nfpyramid = build_pyramid(im, N)\n",
    "\n",
    "for f, nf in zip(fpyramid, nfpyramid):\n",
    "\n",
    "    plt.figure(figsize=[7, 7])\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(f, cmap=plt.cm.gray, interpolation=\"nearest\")\n",
    "    plt.title(\"guaussian pyramid\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(nf, cmap=plt.cm.gray, interpolation=\"nearest\")\n",
    "    plt.title(\"subsampling pyramid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageplot(f, str='', sbpt=[]):\n",
    "    \"\"\"\n",
    "        Use nearest neighbor interpolation for the display.\n",
    "    \"\"\"\n",
    "    if sbpt != []:\n",
    "        plt.subplot(sbpt[0], sbpt[1], sbpt[2])\n",
    "    imgplot = plt.imshow(f, interpolation='nearest')\n",
    "    imgplot.set_cmap('gray')\n",
    "    if str != '':\n",
    "        plt.title(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageplot(-im, '-M', [1,2,1])\n",
    "imageplot(im[::-1,:], 'Flipped', [1,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blurring is achieved by computing a convolution with a kernel.\n",
    "\n",
    "Compute the low pass Gaussian kernel. Warning, the indexes needs to be modulo n in order to use FFTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 7\n",
    "n = 256\n",
    "t = np.concatenate((np.arange(0, n / 2 + 1), np.arange(-n / 2, -1)))\n",
    "[Y, X] = np.meshgrid(t, t)\n",
    "h = np.exp(-(X**2 + Y**2) / (2.0 * float(sigma) ** 2))\n",
    "h = h / sum(h)\n",
    "imageplot(np.fft.fftshift(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the periodic convolution ussing FFTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mh = np.real(np.fft.ifft2(np.fft.fft2(im) * np.fft.fft2(h)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageplot(im, \"Image\", [1, 2, 1])\n",
    "imageplot(Mh, \"Blurred\", [1, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several differential and convolution operators are implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(f):\n",
    "    \"\"\"\n",
    "    Compute a finite difference approximation of the gradient of a 2D image, assuming periodic BC.\n",
    "    \"\"\"\n",
    "    S = f.shape\n",
    "    #   g = np.zeros([n[0], n[1], 2]);\n",
    "    s0 = np.concatenate((np.arange(1, S[0]), [0]))\n",
    "    s1 = np.concatenate((np.arange(1, S[1]), [0]))\n",
    "    g = np.dstack((f[s0, :] - f, f[:, s1] - f))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = grad(im)\n",
    "imageplot(G[:,:,0], 'd/ dx', [1, 2, 1])\n",
    "imageplot(G[:,:,1], 'd/ dy', [1, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourier Transform\n",
    "The 2D Fourier transform can be used to perform low pass approximation and interpolation (by zero padding).\n",
    "\n",
    "Compute and display the Fourier transform (display over a log scale). The function fftshift is useful to put the 0 low frequency in the middle. After fftshift, the zero frequency is located at position (n/2+1,n/2+1)\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mf = np.fft.fft2(im)\n",
    "Lf = np.fft.fftshift(np.log(abs(Mf) + 1e-1))\n",
    "imageplot(im, 'Image', [1, 2, 1])\n",
    "imageplot(Lf, 'Fourier transform', [1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "separators = \"; \", \", \", \" \", \".\"\n",
    "\n",
    "def statistics_in_word(word):\n",
    "    dict = {}\n",
    "    for each_char in word:\n",
    "        if not(each_char in dict):\n",
    "            dict[each_char] = 1\n",
    "        else:\n",
    "            dict[each_char] += 1\n",
    "    return dict\n",
    "            \n",
    "# Solution for requiremnet 01\n",
    "print(\"Solution for requiremnet 01\")\n",
    "def tokenizing(str):\n",
    "    list_tokens = re.split(r'[ ,.]', str)\n",
    "    for token in list_tokens:\n",
    "        if token == '':\n",
    "            list_tokens.remove(token)\n",
    "    return list_tokens\n",
    "            \n",
    "print('Tokenize')\n",
    "print(tokenizing(string))\n",
    "\n",
    "# Solution for requiremnet 02\n",
    "print(\"Solution for requiremnet 02\")\n",
    "def counting(list_tokens):\n",
    "    print('Statistics')\n",
    "    for each_token in list_tokens:\n",
    "        print(each_token + \":\")\n",
    "        print(statistics_in_word(each_token))\n",
    "        \n",
    "    \n",
    "counting(tokenizing(string))\n",
    "\n",
    "# custome tokenizer\n",
    "def custom_tokenizer(sepr_list, str_to_split):\n",
    "    # create regular expression dynamically\n",
    "    regular_exp = '|'.join(map(re.escape, sepr_list))\n",
    "    return re.split(regular_exp, str_to_split)\n",
    "\n",
    "print('Custome tokenizer')\n",
    "print(custom_tokenizer(separators, string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to NLP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: Tokenize and count the number of characters in each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the following sentence: \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "Provide a list of the number of alphabetic characters in each word in the order they appear in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "string = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "separators = [\";\", \",\", \" \", \".\"]\n",
    "\n",
    "def statistics_in_word(word):\n",
    "    \"\"\"Count the occurrences of each character in the word.\"\"\"\n",
    "    char_count = defaultdict(int)  # Use defaultdict for cleaner code\n",
    "    for char in word:\n",
    "        char_count[char] += 1\n",
    "    return dict(char_count)\n",
    "\n",
    "# Solution for requirement 01\n",
    "print(\"Solution for requirement 01\")\n",
    "\n",
    "def tokenizing(input_string):\n",
    "    \"\"\"Tokenize the input string into words, removing empty tokens.\"\"\"\n",
    "    list_tokens = re.split(r\"[ ,.]\", input_string)\n",
    "    return [token for token in list_tokens if token]  # List comprehension to filter out empty tokens\n",
    "\n",
    "print(\"Tokenize:\")\n",
    "tokens = tokenizing(string)\n",
    "print(tokens)\n",
    "\n",
    "# Solution for requirement 02\n",
    "print(\"Solution for requirement 02\")\n",
    "\n",
    "def counting(tokens):\n",
    "    \"\"\"Print the character statistics for each token.\"\"\"\n",
    "    print(\"Statistics:\")\n",
    "    for token in tokens:\n",
    "        print(f\"{token}: {statistics_in_word(token)}\")\n",
    "\n",
    "counting(tokens)\n",
    "\n",
    "# Custom tokenizer\n",
    "def custom_tokenizer(separators, str_to_split):\n",
    "    \"\"\"Tokenize the input string based on a list of separators.\"\"\"\n",
    "    # Create a regular expression dynamically\n",
    "    regular_exp = \"|\".join(map(re.escape, separators))\n",
    "    return re.split(regular_exp, str_to_split)\n",
    "\n",
    "print(\"Custom tokenizer:\")\n",
    "print(custom_tokenizer(separators, string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
